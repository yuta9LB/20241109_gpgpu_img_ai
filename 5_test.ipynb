{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最終テスト"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## やったこと\n",
    "- \n",
    "- \n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "from unet import UNet\n",
    "from pspnet import PSPNet\n",
    "from util import compute_iou\n",
    "\n",
    "\n",
    "# VOC2012で用いるラベル\n",
    "CLASSES = ['backgrounds','aeroplane','bicycle','bird','boat','bottle',\n",
    "            'bus','car' ,'cat','chair','cow', \n",
    "            'diningtable','dog','horse','motorbike','person', \n",
    "            'potted plant', 'sheep', 'sofa', 'train', 'monitor','unlabeld'\n",
    "            ]\n",
    "\n",
    "# カラーパレットの作成\n",
    "COLOR_PALETTE = np.array(Image.open(\"./VOCdevkit/VOC2012_sample/SegmentationClass/2007_000170.png\").getpalette()).reshape(-1,3)\n",
    "COLOR_PALETTE = COLOR_PALETTE.tolist()[:len(CLASSES)]\n",
    "\n",
    "# データディレクトリ\n",
    "img_dir = 'VOCdevkit/VOC2012_sample/JPEGImages'\n",
    "gt_dir = 'VOCdevkit/VOC2012_sample/SegmentationClass'\n",
    "\n",
    "# こんかいしようするデータのID\n",
    "train_list = ['2007_000032', '2007_000648', '2007_001225', '2007_002488']\n",
    "test_list = ['2007_000033', '2007_001763', '2007_003367']\n",
    "\n",
    "train_ious = 0\n",
    "test_ious = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNetの場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論結果の可視化\n",
    "def visualize(model, img_id, img_dir, gt_dir, device='cpu'):\n",
    "    img_path = os.path.join(img_dir, img_id) + \".jpg\"\n",
    "    gt_path = os.path.join(gt_dir, img_id) + \".png\"\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 入力画像の前処理 (PIL画像 -> Tensor)\n",
    "        inp_tensor = transforms.functional.to_tensor(Image.open(img_path))\n",
    "        inp_resized = transforms.Resize(size=(256, 256), interpolation=transforms.InterpolationMode.NEAREST)(inp_tensor)\n",
    "        inp_normalized = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(inp_resized)\n",
    "        inp = inp_normalized.unsqueeze(0)\n",
    "\n",
    "        # 正解画像の前処理 (PIL画像 -> NumPy -> Tensor)\n",
    "        gt_np = np.asarray(Image.open(gt_path))\n",
    "        gt_np = np.where(gt_np == 255, 0, gt_np)  # 範囲外の255を0に置換（または別のインデックスに）\n",
    "\n",
    "        gt_tensor = torch.tensor(gt_np, dtype=torch.long)\n",
    "        gt_tensor = gt_tensor.unsqueeze(0)\n",
    "        gt_resized = transforms.Resize(size=(256, 256), interpolation=transforms.InterpolationMode.NEAREST)(gt_tensor)\n",
    "\n",
    "        # 予測\n",
    "        pred = model(inp)\n",
    "        iou = compute_iou(pred, gt_resized)\n",
    "        print(f'IoU: {iou}')\n",
    "\n",
    "        inp_np = (inp_resized.numpy().transpose(1, 2, 0) * 255).astype(np.uint8)  # 表示用スケール\n",
    "        pred_np = torch.argmax(pred, dim=1).cpu().detach().numpy()[0]\n",
    "        pred_np = np.clip(pred_np, 0, len(COLOR_PALETTE) - 1).astype(np.int32)\n",
    "        gt_resized = gt_resized.squeeze(0).detach().numpy().astype(np.int32)\n",
    "\n",
    "        # カラーパレットの適用\n",
    "        img_gt = np.array([[COLOR_PALETTE[gt_resized[i, j]] for j in range(256)] for i in range(256)], dtype=np.uint8)\n",
    "        img_pred = np.array([[COLOR_PALETTE[pred_np[i, j]] for j in range(256)] for i in range(256)], dtype=np.uint8)\n",
    "\n",
    "    # プロット\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    for i, im in enumerate([inp_np, img_gt, img_pred]):\n",
    "        ax = fig.add_subplot(1, 3, i+1)\n",
    "        ax.imshow(im)\n",
    "        ax.set_title([\"Input\", \"Ground Truth\", \"Prediction\"][i])\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return iou\n",
    "\n",
    "model = UNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSPNetの場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論結果の可視化\n",
    "def visualize(model, img_id, img_dir, gt_dir, device='cpu'):\n",
    "    img_path = os.path.join(img_dir, img_id) + \".jpg\"\n",
    "    gt_path = os.path.join(gt_dir, img_id) + \".png\"\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 入力画像の前処理 (PIL画像 -> Tensor)\n",
    "        inp_tensor = transforms.functional.to_tensor(Image.open(img_path))\n",
    "        inp_resized = transforms.Resize(size=(256, 256), interpolation=transforms.InterpolationMode.NEAREST)(inp_tensor)\n",
    "        inp_normalized = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(inp_resized)\n",
    "        inp = inp_normalized.unsqueeze(0)\n",
    "\n",
    "        # 正解画像の前処理 (PIL画像 -> NumPy -> Tensor)\n",
    "        gt_np = np.asarray(Image.open(gt_path))\n",
    "        gt_np = np.where(gt_np == 255, 0, gt_np)  # 範囲外の255を0に置換（または別のインデックスに）\n",
    "\n",
    "        gt_tensor = torch.tensor(gt_np, dtype=torch.long)\n",
    "        gt_tensor = gt_tensor.unsqueeze(0)\n",
    "        gt_resized = transforms.Resize(size=(256, 256), interpolation=transforms.InterpolationMode.NEAREST)(gt_tensor)\n",
    "\n",
    "        # 予測\n",
    "        pred, _ = model(inp)\n",
    "        iou = compute_iou(pred, gt_resized)\n",
    "        print(f'IoU: {iou}')\n",
    "\n",
    "        inp_np = (inp_resized.numpy().transpose(1, 2, 0) * 255).astype(np.uint8)  # 表示用スケール\n",
    "        pred_np = torch.argmax(pred, dim=1).cpu().detach().numpy()[0]\n",
    "        pred_np = np.clip(pred_np, 0, len(COLOR_PALETTE) - 1).astype(np.int32)\n",
    "        gt_resized = gt_resized.squeeze(0).detach().numpy().astype(np.int32)\n",
    "\n",
    "        # カラーパレットの適用\n",
    "        img_gt = np.array([[COLOR_PALETTE[gt_resized[i, j]] for j in range(256)] for i in range(256)], dtype=np.uint8)\n",
    "        img_pred = np.array([[COLOR_PALETTE[pred_np[i, j]] for j in range(256)] for i in range(256)], dtype=np.uint8)\n",
    "\n",
    "    # プロット\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    for i, im in enumerate([inp_np, img_gt, img_pred]):\n",
    "        ax = fig.add_subplot(1, 3, i+1)\n",
    "        ax.imshow(im)\n",
    "        ax.set_title([\"Input\", \"Ground Truth\", \"Prediction\"][i])\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return iou\n",
    "\n",
    "model = PSPNet(n_classes=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重みの入力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkp_path = 'Path/to/chkp_path.pth'\n",
    "checkpoint = torch.load(chkp_path, map_location='cpu', weights_only=True)\n",
    "model.load_state_dict(checkpoint['model_state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in train_list:\n",
    "    iou = visualize(model, id, img_dir, gt_dir)\n",
    "    train_ious += iou\n",
    "train_ious_ave = train_ious / len(train_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in test_list:\n",
    "    iou = visualize(model, id, img_dir, gt_dir)\n",
    "    test_ious += iou\n",
    "test_ious_ave = test_ious / len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score')\n",
    "print(f'Train IoU: {train_ious_ave}')\n",
    "print(f'Test IoU: {test_ious_ave}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 考察\n",
    "- \n",
    "- \n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
