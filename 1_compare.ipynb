{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPUとGPUの比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これから機械学習において、CPUとGPUにどのような違いが出るかを体験していただきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリのインストール\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 行列の内積計算\n",
    "CPUとGPUで行列の内積計算の速度を比較します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリのインポート\n",
    "import numpy as np\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行列のサイズを設定（大きいほど計算が重くなり、差がわかりやすくなります）\n",
    "matrix_size = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>CPU</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPUでの計算\n",
    "print(\"CPU計算開始...\")\n",
    "A_cpu = np.random.rand(matrix_size, matrix_size)\n",
    "B_cpu = np.random.rand(matrix_size, matrix_size)\n",
    "start_time = time.time()\n",
    "C_cpu = np.dot(A_cpu, B_cpu)\n",
    "cpu_time = time.time() - start_time\n",
    "print(f\"CPUでの計算時間: {cpu_time:.4f} 秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>GPU</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPU計算開始...\")\n",
    "A_gpu = torch.rand(matrix_size, matrix_size, device='cuda')\n",
    "B_gpu = torch.rand(matrix_size, matrix_size, device='cuda')\n",
    "start_time = time.time()\n",
    "C_gpu = torch.mm(A_gpu, B_gpu)\n",
    "gpu_time = time.time() - start_time\n",
    "print(f\"GPUでの計算時間: {gpu_time:.4f} 秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPUでは、数千の小さなコアを持っており、同時に大量の計算をすることがかのうであるため、大規模な行列の計算などを高速に処理することが可能となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 機械学習\n",
    "ディープラーニングでは大規模な行列同士の積が必要となります。<br>\n",
    "そのため、GPUの並列処理能力が大きな役割を果たします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は学習データ<b>300枚</b>、テストデータ<b>100枚</b>を用いて、<b>1回</b>(1エポック)訓練を行います。<br>\n",
    "通常は<b>何千、何万以上</b>のデータを用いて<b>何百回</b>も繰り返し訓練し、精度を上げていきます。（タスクやモデルにもよりますが）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用するライブラリのインポート\n",
    "import math\n",
    "import tqdm\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from unet import UNet\n",
    "from dataset import VOCDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from util import DiceCrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOC2012で用いるラベル\n",
    "CLASSES = ['backgrounds','aeroplane','bicycle','bird','boat','bottle',\n",
    "            'bus','car' ,'cat','chair','cow', \n",
    "            'diningtable','dog','horse','motorbike','person', \n",
    "            'potted plant', 'sheep', 'sofa', 'train', 'monitor','unlabeld'\n",
    "            ]\n",
    "\n",
    "# カラーパレットの作成\n",
    "COLOR_PALETTE = np.array(Image.open(\"./VOCdevkit/VOC2012_sample/SegmentationClass/2007_000170.png\").getpalette()).reshape(-1,3)\n",
    "COLOR_PALETTE = COLOR_PALETTE.tolist()[:len(CLASSES)]\n",
    "\n",
    "# 使用データのリストファイル\n",
    "train_list_path = 'VOCdevkit/VOC2012_sample/listfile/train_list_300.txt'\n",
    "val_list_path = 'VOCdevkit/VOC2012_sample/listfile/val_list_100.txt'\n",
    "\n",
    "# データのあるディレクトリ\n",
    "img_dir = 'VOCdevkit/VOC2012_sample/JPEGImages'\n",
    "gt_dir = 'VOCdevkit/VOC2012_sample/SegmentationClass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# リストファイルの読み込み\n",
    "with open(train_list_path, 'r') as f:\n",
    "    train_list = f.read().splitlines()\n",
    "with open(val_list_path, 'r') as g:\n",
    "    val_list = g.read().splitlines()\n",
    "\n",
    "# データセット作成\n",
    "train_ds = VOCDataset(img_list=train_list, img_dir=img_dir, gt_dir=gt_dir)\n",
    "val_ds = VOCDataset(img_list=val_list, img_dir=img_dir, gt_dir=gt_dir)\n",
    "print(f\"len(train_data): {train_ds.__len__()}\")\n",
    "print(f\"len(test_data): {val_ds.__len__()}\")\n",
    "\n",
    "# データローダーの作成\n",
    "train_dl = DataLoader(train_ds, batch_size=16, num_workers=4, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=16, num_workers=4, shuffle=True)\n",
    "\n",
    "# その他設定\n",
    "epochs = 1 # エポック数\n",
    "model = UNet() # 機械学習モデル\n",
    "criterion =  DiceCrossEntropyLoss() # 損失関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練\n",
    "def train(dataloader, model, optimizer, criterion, device):\n",
    "    start = time.time()\n",
    "\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    batch_size = dataloader.batch_size\n",
    "    step_total = math.ceil(size/batch_size)\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with tqdm.tqdm(enumerate(dataloader), total=step_total) as pbar:\n",
    "        for batch, item in pbar:\n",
    "            inp, gt = item[0].to(device), item[1].to(device)\n",
    "\n",
    "            # 推論\n",
    "            pred = model(inp)\n",
    "\n",
    "            # 損失誤差を計算\n",
    "            loss = criterion(pred, gt)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # バックプロパゲーション\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # プログレスバーに損失を表示\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_loss = total_loss / step_total\n",
    "        # print(f\"Train Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "# テスト\n",
    "def test(dataloader, model, criterion, device):\n",
    "    start = time.time()\n",
    "\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    batch_size = dataloader.batch_size\n",
    "    step_total = math.ceil(size/batch_size)\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for item in dataloader:\n",
    "            inp, gt = item[0].to(device), item[1].to(device)\n",
    "            pred = model(inp)\n",
    "            loss = criterion(pred, gt)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / step_total\n",
    "        # print(f\"Val Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "    end = time.time()\n",
    "    return end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>CPU</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # 最適化手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time = train(train_dl, model, optimizer, criterion, device)\n",
    "test_time = test(val_dl, model, criterion, device)\n",
    "print(f'学習時間：{train_time}[s]')\n",
    "print(f'評価時間：{test_time}[s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>GPU</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # 最適化手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time = train(train_dl, model, optimizer, criterion, device)\n",
    "test_time = test(val_dl, model, criterion, device)\n",
    "print(f'学習時間：{train_time}')\n",
    "print(f'評価時間：{test_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1回（1エポック）の訓練でも大きな違いが出ました。<br>\n",
    "通常これを何百回と繰り返すため、良いGPUが必要となります。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
