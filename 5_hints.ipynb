{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 機械学習関連知識"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済の重み\n",
    "入力データが出力にどれだけ影響を与えるかを示すパラメータ  \n",
    "訓練の過程で更新され続ける値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# chkp_pathのパスを指定して、重みを読みこみそこから再開できる\n",
    "chkp_path = None # 重みの初期値\n",
    "continuation = False # 訓練を続きから再開する場合True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習率\n",
    "機械学習モデルの訓練中にパラメータ（重み）を更新する際、どの程度の幅で変化させるかを決める重要なハイパーパラメータ  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 学習率\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 過学習\n",
    "<img src='img/over_fitting.png'></img>  \n",
    "引用元: [zeroone[G検定（AI・機械学習）用語集]](https://zero2one.jp/ai-word/overfitting-2/)\n",
    "### 特徴\n",
    "- モデルが訓練データの細かいノイズや例外にまで適応しすぎ、汎化性能（新しいデータに対する予測力）が低下すること\n",
    "- 訓練データでの精度が非常に高い一方、テストデータでの精度が低くなること\n",
    "\n",
    "### 防ぐ方法\n",
    "- データを増やす\n",
    "- 正則化 (Regularization)\n",
    "- クロスバリデーション (Cross-Validation)\n",
    "- モデルの単純化\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ拡張 (Data Augmentation)\n",
    "元の訓練データをさまざまな方法で変形・加工することで、データの量を人工的に増やし、モデルの汎化性能を向上させる手法\n",
    "\n",
    "**画像の場合の手法**\n",
    "- 回転: 画像を一定の角度で回転させる。\n",
    "- 反転・フリップ: 左右や上下に画像を反転させる。\n",
    "- ズーム: 拡大・縮小を行う。\n",
    "- 平行移動: 画像を上下左右にずらす。\n",
    "- 色調変化: 明るさやコントラスト、色相などを変える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# data_augmentation = Trueにすることデータアーギュメント\n",
    "data_augmentation = True\n",
    "\n",
    "# dataset.py\n",
    "# augment関数内でデータ拡張を行っている。今回は水平反転と回転。さらに追加してもOK\n",
    "def augment(self, img, gt):\n",
    "    # 同じシードでランダム変換を適用\n",
    "    seed = torch.randint(0, 2**32, (1,)).item()\n",
    "    \n",
    "    # ランダム水平反転\n",
    "    torch.manual_seed(seed)\n",
    "    img = self.random_flip(img)\n",
    "    torch.manual_seed(seed)\n",
    "    gt = self.random_flip(gt)\n",
    "    \n",
    "    # ランダム回転\n",
    "    torch.manual_seed(seed)\n",
    "    img = self.random_rotation(img)\n",
    "    torch.manual_seed(seed)\n",
    "    gt = self.random_rotation(gt)\n",
    "    \n",
    "    return img, gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正則化\n",
    "機械学習モデルの複雑さを抑えるために、モデルのパラメータに制約を加え、過学習を防ぐ手法  \n",
    "例）L1正則化（Lasso）、L2正則化（Ridge）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# weight_decayを入れることでL2正則化\n",
    "torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ドロップアウト（Dropout）\n",
    "正則化手法の一つで、訓練中にランダムに一部のノード（ニューロン）を無効にして学習を行う方法 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ドロップアウト\n",
    "# pはドロップアウト率（0.2~0.5が一般的）\n",
    "nn.Dropout(p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クロスエントロピー損失のクラスごとの重み（weight）\n",
    "これを指定することで、各クラスごとの重みを指定することができる。  \n",
    "最初の値から順番に'CLASSES'の値を示す。  \n",
    "CLASSES = ['backgrounds','aeroplane','bicycle','bird','boat','bottle', 'bus','car' ,'cat','chair','cow', 'diningtable','dog','horse','motorbike','person', 'potted plant', 'sheep', 'sofa', 'train', 'monitor','unlabeld']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "weight = torch.tensor([0.3, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失関数の比率（dice_weight）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dice_weight = 0.5\n",
    "\n",
    "# util.py\n",
    "# class DiceCrossEntropyLoss\n",
    "# 複合損失の計算\n",
    "total_loss = (1 - self.dice_weight) * ce_loss + self.dice_weight * dice_loss"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
