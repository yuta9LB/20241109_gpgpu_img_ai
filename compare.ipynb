{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPUとGPUの比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これから機械学習において、CPUとGPUにどのような違いが出るかを体験していただきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリのインストール\n",
    "!pip install -r requirement.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 行列の内積計算\n",
    "CPUとGPUで行列の内積計算の速度を比較します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリのインポート\n",
    "import numpy as np\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行列のサイズを設定（大きいほど計算が重くなり、差がわかりやすくなります）\n",
    "matrix_size = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>CPU</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPUでの計算\n",
    "print(\"CPU計算開始...\")\n",
    "A_cpu = np.random.rand(matrix_size, matrix_size)\n",
    "B_cpu = np.random.rand(matrix_size, matrix_size)\n",
    "start_time = time.time()\n",
    "C_cpu = np.dot(A_cpu, B_cpu)\n",
    "cpu_time = time.time() - start_time\n",
    "print(f\"CPUでの計算時間: {cpu_time:.4f} 秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>GPU</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPU計算開始...\")\n",
    "A_gpu = torch.rand(matrix_size, matrix_size, device='cuda')\n",
    "B_gpu = torch.rand(matrix_size, matrix_size, device='cuda')\n",
    "start_time = time.time()\n",
    "C_gpu = torch.mm(A_gpu, B_gpu)\n",
    "gpu_time = time.time() - start_time\n",
    "print(f\"GPUでの計算時間: {gpu_time:.4f} 秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPUでは、数千の小さなコアを持っており、同時に大量の計算をすることがかのうであるため、大規模な行列の計算などを高速に処理することが可能となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 機械学習\n",
    "ディープラーニングでは大規模な行列同士の積が必要となります。<br>\n",
    "そのため、GPUの並列処理能力が大きな役割を果たします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は学習データ<b>300枚</b>、テストデータ<b>100枚</b>を用いて、<b>1回</b>(1エポック)訓練を行います。<br>\n",
    "通常は<b>何千、何万以上</b>のデータを用いて<b>何百回</b>も繰り返し訓練し、精度を上げていきます。（タスクやモデルにもよりますが）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用するライブラリのインポート\n",
    "import math\n",
    "import tqdm\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from unet import UNet\n",
    "from dataset import VOCDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOC2012で用いるラベル\n",
    "CLASSES = ['backgrounds','aeroplane','bicycle','bird','boat','bottle',\n",
    "            'bus','car' ,'cat','chair','cow', \n",
    "            'diningtable','dog','horse','motorbike','person', \n",
    "            'potted plant', 'sheep', 'sofa', 'train', 'monitor','unlabeld'\n",
    "            ]\n",
    "\n",
    "# カラーパレットの作成\n",
    "COLOR_PALETTE = np.array(Image.open(\"./VOCdevkit/VOC2012_sample/SegmentationClass/2007_000170.png\").getpalette()).reshape(-1,3)\n",
    "COLOR_PALETTE = COLOR_PALETTE.tolist()[:len(CLASSES)]\n",
    "\n",
    "# 使用データのリストファイル\n",
    "train_list_path = 'VOCdevkit/VOC2012_sample/listfile/train_list_300.txt'\n",
    "val_list_path = 'VOCdevkit/VOC2012_sample/listfile/val_list_100.txt'\n",
    "\n",
    "# データのあるディレクトリ\n",
    "img_dir = 'VOCdevkit/VOC2012_sample/JPEGImages'\n",
    "gt_dir = 'VOCdevkit/VOC2012_sample/SegmentationClass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# リストファイルの読み込み\n",
    "with open(train_list_path, 'r') as f:\n",
    "    train_list = f.read().splitlines()\n",
    "with open(val_list_path, 'r') as g:\n",
    "    val_list = g.read().splitlines()\n",
    "\n",
    "# データセット作成\n",
    "train_ds = VOCDataset(img_list=train_list, phase='trian', img_dir=img_dir, gt_dir=gt_dir)\n",
    "val_ds = VOCDataset(img_list=val_list, phase='val', img_dir=img_dir, gt_dir=gt_dir)\n",
    "print(f\"len(train_data): {train_ds.__len__()}\")\n",
    "print(f\"len(test_data): {val_ds.__len__()}\")\n",
    "\n",
    "# データローダーの作成\n",
    "train_dl = DataLoader(train_ds, batch_size=16, num_workers=4, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=16, num_workers=4, shuffle=True)\n",
    "\n",
    "# その他設定\n",
    "epochs = 1 # エポック数\n",
    "model = UNet() # 機械学習モデル\n",
    "criterion =  nn.CrossEntropyLoss() # 損失関数\n",
    "\n",
    "# 重みの読み込み。\n",
    "chkp_path = 'weights/20241105_demo_ep2.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練\n",
    "def train(dataloader, model, optimizer, criterion, device):\n",
    "    start = time.time()\n",
    "\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    batch_size = dataloader.batch_size\n",
    "    step_total = math.ceil(size/batch_size)\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with tqdm.tqdm(enumerate(dataloader), total=step_total) as pbar:\n",
    "        for batch, item in pbar:\n",
    "            inp, gt = item[0].to(device), item[1].to(device)\n",
    "\n",
    "            # 推論\n",
    "            pred = model(inp)\n",
    "\n",
    "            # 損失誤差を計算\n",
    "            loss = criterion(pred, gt)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # バックプロパゲーション\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # プログレスバーに損失を表示\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_loss = total_loss / step_total\n",
    "        # print(f\"Train Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "# テスト\n",
    "def test(dataloader, model, criterion, device):\n",
    "    start = time.time()\n",
    "\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    batch_size = dataloader.batch_size\n",
    "    step_total = math.ceil(size/batch_size)\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for item in dataloader:\n",
    "            inp, gt = item[0].to(device), item[1].to(device)\n",
    "            pred = model(inp)\n",
    "            loss = criterion(pred, gt)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / step_total\n",
    "        # print(f\"Val Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "# 推論結果の可視化\n",
    "def visualize(model, dataloader):\n",
    "    model.to('cpu')\n",
    "    model.softmax = True\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inp, gt in dataloader:\n",
    "            inp = inp.to('cpu')\n",
    "            pred = model(inp)\n",
    "\n",
    "            gt_ = torch.argmax(gt, dim=1).cpu().numpy()\n",
    "            pred_ = torch.argmax(pred, dim=1).cpu().numpy()\n",
    "\n",
    "            k = 0\n",
    "            inp_np = inp[k].numpy().transpose(1, 2, 0)\n",
    "            gt_np = gt_[k]\n",
    "            pred_np = pred_[k]\n",
    "\n",
    "            img_gt = [[0 for j in range(256)] for i in range(256)]\n",
    "            img_pred = [[0 for j in range(256)] for i in range(256)]\n",
    "\n",
    "            for height in range(256):\n",
    "                for width in range(256):\n",
    "                    index_1 = gt_np[height,width]\n",
    "                    index_2 = pred_np[height,width]\n",
    "                    rgb_1 = COLOR_PALETTE[index_1]\n",
    "                    rgb_2 = COLOR_PALETTE[index_2]\n",
    "                    img_gt[height][width] = rgb_1\n",
    "                    img_pred[height][width] = rgb_2\n",
    "\n",
    "            img_gt = np.asarray(img_gt)\n",
    "            img_pred = np.asarray(img_pred)\n",
    "            inp_np = inp_np.astype(np.uint8)\n",
    "            break\n",
    "        \n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    for i, im in enumerate([inp_np, img_gt, img_pred]):\n",
    "        fig.add_subplot(2,3,i+1).set_title(str(i))\n",
    "        plt.imshow(im)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>CPU</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "checkpoint = torch.load(chkp_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # 最適化手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time = train(train_dl, model, optimizer, criterion, device)\n",
    "test_time = test(val_dl, model, criterion, device)\n",
    "print(f'学習時間：{train_time}[s]')\n",
    "print(f'評価時間：{test_time}[s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>GPU</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "checkpoint = torch.load(chkp_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # 最適化手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time = train(train_dl, model, optimizer, criterion, device)\n",
    "test_time = test(val_dl, model, criterion, device)\n",
    "print(f'学習時間：{train_time}')\n",
    "print(f'評価時間：{test_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1回（1エポック）の訓練でも大きな違いが出ました。<br>\n",
    "通常これを何百回と繰り返すため、良いGPUが必要となります。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
