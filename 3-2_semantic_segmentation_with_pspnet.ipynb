{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSPNetによる訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pspnet import PSPNet\n",
    "from dataset import VOCDataset\n",
    "from util import DiceCrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 既定変数\n",
    "基本的に変更の必要なし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOC2012で用いるラベル\n",
    "CLASSES = ['backgrounds','aeroplane','bicycle','bird','boat','bottle',\n",
    "            'bus','car' ,'cat','chair','cow', \n",
    "            'diningtable','dog','horse','motorbike','person', \n",
    "            'potted plant', 'sheep', 'sofa', 'train', 'monitor','unlabeld'\n",
    "            ]\n",
    "\n",
    "# カラーパレットの作成\n",
    "COLOR_PALETTE = np.array(Image.open(\"./VOCdevkit/VOC2012_sample/SegmentationClass/2007_000170.png\").getpalette()).reshape(-1,3)\n",
    "COLOR_PALETTE = COLOR_PALETTE.tolist()[:len(CLASSES)]\n",
    "\n",
    "# データディレクトリ\n",
    "img_dir = 'VOCdevkit/VOC2012_sample/JPEGImages'\n",
    "gt_dir = 'VOCdevkit/VOC2012_sample/SegmentationClass'\n",
    "\n",
    "initial_epoch = 0\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\" # デバイスの設定\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "model = PSPNet(n_classes=22) # モデル\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行周りの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのリストファイル\n",
    "train_list_path = 'VOCdevkit/VOC2012_sample/listfile/train_list_300.txt'\n",
    "val_list_path = 'VOCdevkit/VOC2012_sample/listfile/val_list_100.txt'\n",
    "\n",
    "# 保存先\n",
    "save_dir = './pspnet_sample' # 訓練ログ保存ディレクトリ\n",
    "save_name_prefix = 'pspnet_sample' # 訓練ログ保存名\n",
    "csv_path = os.path.join(save_dir, f'{save_name_prefix}.csv')\n",
    "\n",
    "# データローダーの引数（大きいほど高速に動作するが、GPUの性能により限界がある）\n",
    "batch_size=16 # バッチサイズ\n",
    "num_workers=8 # ワーカープロセス数（データ読み込みの並列数）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習周りの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習関連\n",
    "epochs = 100 # エポック\n",
    "lr = 0.01 # 学習率\n",
    "\n",
    "# 重み\n",
    "chkp_path = None # 重みの初期値\n",
    "continuation = False # 訓練を続きから再開する場合True\n",
    "\n",
    "# データアーギュメント\n",
    "data_augmentation = False\n",
    "\n",
    "# 損失関数関連\n",
    "weight = None\n",
    "dice_weight = 0.5\n",
    "aux_weight = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの読み込み、損失関数・最適化手法の定義、重みの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# リストファイルの読み込み\n",
    "with open(train_list_path, 'r') as f:\n",
    "    train_list = f.read().splitlines()\n",
    "with open(val_list_path, 'r') as g:\n",
    "    val_list = g.read().splitlines()\n",
    "\n",
    "# データセットの作成\n",
    "train_ds = VOCDataset(img_list=train_list, img_dir=img_dir, gt_dir=gt_dir, data_augmentation=data_augmentation)\n",
    "val_ds = VOCDataset(img_list=val_list, img_dir=img_dir, gt_dir=gt_dir)\n",
    "print(f\"len(train_data): {train_ds.__len__()}\")\n",
    "print(f\"len(test_data): {val_ds.__len__()}\")\n",
    "\n",
    "# データローダーの作成\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "\n",
    "# 保存ディレクトリの作成\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "# 最適化手法\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr) \n",
    "\n",
    "# 重みの読み込み。\n",
    "if chkp_path is not None:\n",
    "    checkpoint = torch.load(chkp_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "    if continuation == True:\n",
    "        initial_epoch = checkpoint[\"epoch\"] + 1\n",
    "\n",
    "if weight is not None:\n",
    "    weight = weight.to(device)\n",
    "criterion =  DiceCrossEntropyLoss(weight=weight, dice_weight=dice_weight) # 損失関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練\n",
    "def train(dataloader, model, optimizer, criterion, aux_weight, device):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    batch_size = dataloader.batch_size\n",
    "    step_total = math.ceil(size/batch_size)\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with tqdm.tqdm(enumerate(dataloader), total=step_total) as pbar:\n",
    "        for batch, item in pbar:\n",
    "            inp, gt = item[0].to(device), item[1].to(device)\n",
    "\n",
    "            # 推論\n",
    "            pred, pred_aux = model(inp)\n",
    "\n",
    "            # 損失誤差を計算\n",
    "            loss = criterion(pred, gt) + aux_weight * criterion(pred_aux, gt)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # バックプロパゲーション\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # プログレスバーに損失を表示\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_loss = total_loss / step_total\n",
    "        print(f\"Train Loss: {avg_loss:.4f}\")\n",
    "    return avg_loss\n",
    "\n",
    "# テスト\n",
    "def test(dataloader, model, criterion, aux_weight, device):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    batch_size = dataloader.batch_size\n",
    "    step_total = math.ceil(size/batch_size)\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for item in dataloader:\n",
    "            inp, gt = item[0].to(device), item[1].to(device)\n",
    "            pred, pred_aux = model(inp)\n",
    "            loss = criterion(pred, gt) + aux_weight * criterion(pred_aux, gt)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / step_total\n",
    "        print(f\"Val Loss: {avg_loss:.4f}\")\n",
    "    return avg_loss\n",
    "\n",
    "# 推論結果の可視化\n",
    "def visualize(model, img_id, img_dir, gt_dir, criterion, aux_weight, device='cpu'):\n",
    "    img_path = os.path.join(img_dir, img_id) + \".jpg\"\n",
    "    gt_path = os.path.join(gt_dir, img_id) + \".png\"\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 入力画像の前処理 (PIL画像 -> Tensor)\n",
    "        inp_tensor = transforms.functional.to_tensor(Image.open(img_path))\n",
    "        inp_resized = transforms.Resize(size=(256, 256), interpolation=transforms.InterpolationMode.NEAREST)(inp_tensor)\n",
    "        inp_normalized = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(inp_resized)\n",
    "        inp = inp_normalized.unsqueeze(0)\n",
    "\n",
    "        # 正解画像の前処理 (PIL画像 -> NumPy -> Tensor)\n",
    "        gt_np = np.asarray(Image.open(gt_path))\n",
    "        gt_np = np.where(gt_np == 255, 0, gt_np)  # 範囲外の255を0に置換（または別のインデックスに）\n",
    "\n",
    "        gt_tensor = torch.tensor(gt_np, dtype=torch.long)\n",
    "        gt_tensor = gt_tensor.unsqueeze(0)\n",
    "        gt_resized = transforms.Resize(size=(256, 256), interpolation=transforms.InterpolationMode.NEAREST)(gt_tensor)\n",
    "\n",
    "        # 予測\n",
    "        pred, pred_aux = model(inp)\n",
    "        loss = criterion(pred, gt_resized) + aux_weight * criterion(pred_aux, gt_resized) # loss計算\n",
    "        print(f'Loss: {loss.item()}')\n",
    "\n",
    "        inp_np = (inp_resized.numpy().transpose(1, 2, 0) * 255).astype(np.uint8)  # 表示用スケール\n",
    "        pred_np = torch.argmax(pred, dim=1).cpu().detach().numpy()[0]\n",
    "        pred_np = np.clip(pred_np, 0, len(COLOR_PALETTE) - 1).astype(np.int32)\n",
    "        gt_resized = gt_resized.squeeze(0).detach().numpy().astype(np.int32)\n",
    "\n",
    "        # カラーパレットの適用\n",
    "        img_gt = np.array([[COLOR_PALETTE[gt_resized[i, j]] for j in range(256)] for i in range(256)], dtype=np.uint8)\n",
    "        img_pred = np.array([[COLOR_PALETTE[pred_np[i, j]] for j in range(256)] for i in range(256)], dtype=np.uint8)\n",
    "\n",
    "    # プロット\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    for i, im in enumerate([inp_np, img_gt, img_pred]):\n",
    "        ax = fig.add_subplot(1, 3, i+1)\n",
    "        ax.imshow(im)\n",
    "        ax.set_title([\"Input\", \"Ground Truth\", \"Prediction\"][i])\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(initial_epoch, epochs):\n",
    "    print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "    train_loss = train(train_dl, model, optimizer, criterion, aux_weight, device)\n",
    "    val_loss = test(val_dl, model, criterion, aux_weight, device)\n",
    "\n",
    "    # モデルの重みを保存\n",
    "    torch.save(\n",
    "    {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        },\n",
    "    os.path.join(save_dir, f'{save_name_prefix}_ep{epoch}.pth'),\n",
    "    )\n",
    "\n",
    "    # 訓練ログ記入\n",
    "    if not os.path.exists(csv_path):\n",
    "        with open(csv_path, 'w') as f:\n",
    "            f.write('epoch,train_loss,val_loss\\n')\n",
    "    with open(csv_path, 'a') as f:\n",
    "        f.write(f'{epoch},{train_loss},{val_loss}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 損失のプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = pd.read_csv(csv_path)\n",
    "plt.plot(log_df['epoch'], log_df['train_loss'], label='trian_data')\n",
    "plt.plot(log_df['epoch'], log_df['val_loss'], label='test_data')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "# plt.ylim(0,2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>train data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = '2007_000032' # 好きな画像IDを入れてOK\n",
    "visualize(model, img_id, img_dir, gt_dir, criterion, aux_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = '2007_000648'\n",
    "visualize(model, img_id, img_dir, gt_dir, criterion, aux_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = '2007_001225'\n",
    "visualize(model, img_id, img_dir, gt_dir, criterion, aux_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = '2007_002488'\n",
    "visualize(model, img_id, img_dir, gt_dir, criterion, aux_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>test data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = '2007_000033'\n",
    "visualize(model, img_id, img_dir, gt_dir, criterion, aux_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = '2007_001763'\n",
    "visualize(model, img_id, img_dir, gt_dir, criterion, aux_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = '2007_003367'\n",
    "visualize(model, img_id, img_dir, gt_dir, criterion, aux_weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
